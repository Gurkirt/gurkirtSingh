<!DOCTYPE html>
<!-- saved from url=(0050)http://getbootstrap.com/examples/starter-template/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="personal page of Gurkirt Singh">
    <meta name="author" content="Gurkirt Singh">
    <link rel="icon" href="resources/icons/G.png">
    <title>Gurkirt Singh</title>

    <!-- Bootstrap core CSS -->
    <link href="./bootstrap/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="./bootstrap/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="./bootstrap/style.css" rel="stylesheet">
	<link href="./bootstrap/css" rel="stylesheet" type="text/css">
	
	
    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="./bootstrap/ie-emulation-modes-warning.js"></script>

	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	
	  ga('create', 'UA-81912424-1', 'auto');
	  ga('send', 'pageview');
	
	</script>
	
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  
  </head>
<body>
	<div class="container">
	<div  class="jumbotron">
		
		<div style="float:left; margin-left:-55px;  margin-right:40px"> <img src="resources/me.jpg" height="230"></div>
		<div class="container">
			<h2 class="hh">Gurkirt Singh</h2>
			<h4> <a href="http://cct.brookes.ac.uk/research/isec/artificial-intelligence/index.html">Artificial Intelligence and Vision Group</a></h4>
			<h4><a href="https://www.brookes.ac.uk/">Oxford Brookes University</a></h4>
			<h4>T2.06, Wheatley Campus</h4>
			<h4>Oxford, OX33 1HX</h4>
			<!--<a href = "https://sites.google.com/site/gurkirtcv/"> Visit my personal page on google.sites</a>-->
			<a href="https://scholar.google.com/citations?user=w8XHUMIAAAAJ&hl=en" target="_blank"><img src="resources/icons/google_scholar.png" ></a> 
			<a href="https://github.com/gurkirt/" target="_blank" ><img src="resources/icons/github_alt.png" height="32"></a> 
			<a href="https://uk.linkedin.com/in/gurkirt" target="_blank" ><img src="resources/icons/linkedin.png" height="32"></a>  
			<a href="https://plus.google.com/u/1/+gurkirtsingh" target="_blank" ><img src="resources/icons/google_plus.png" height="32"></a> 
			<a href="http://www.mathworks.com/matlabcentral/profile/authors/1538813-gurkirt-singh" target="_blank" ><img src="resources/icons/matlab.png" height="32"></a>
			
		</div>
	</div>
	</div>
		
	<div class="container">

		<h2 class="hh">About Me (<a href="resources/cv.pdf">CV</a>)</h2>
		<p>
			I am a first year PhD student in 
			<a href="http://cct.brookes.ac.uk/research/isec/artificial-intelligence/index.html">Artificial Intelligence and Vision Group</a>
			at <a href="https://www.brookes.ac.uk/">Oxford Brookes University</a>.
			I am advised by <a href="http://cms.brookes.ac.uk/staff/FabioCuzzolin/">Dr. Fabio Cuzzolin</a>.
			My research is focused on spatio-temporal action detection and prediction in realistic videos.
		</p>	
		<p>	
			Earlier, I was research engineer for two years in imaging and computer vision group at Siemens research India, directed by <a href="http://www.cfar.umd.edu/~kale/">Amit Kale</a>.
			In 2013, I graduated from masters in informatics (MOSIG) program at
			<a href="http://www.grenoble-inp.fr/">Institut National Polytechnique de Grenoble-INPG (School ENSIMAG)</a>
			with specialization in Graphics Vision and Robotics (<a = href="http://mosig.imag.fr/ProgramEN/GVR">GVR</a>).
			I completed my master's thesis under the supervision of <a href="https://team.inria.fr/perception/alumni/evangelidis/">Dr. Georgios Evangelidis</a>
			and <a href="https://team.inria.fr/perception/team-members/radu-patrice-horaud/">Dr. Radu HORAUD</a> at INRIA, Grenoble. 
			I received Bachelor of Technology degree in Electronics and Instrumentation Engineering from <a href="http://www.vit.ac.in/">VIT University</a>, Vellore,
			during which I had chance do an internship at university of Edinburgh under the supervision of <a href="#">Dr. Bob Fisher</a>.
		</p>
	
	</div>
	
	<div class="container">

		<h2 class="hh">News</h2>
		<p>15/07/2016: Our paper on "Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos" is accpted at BMVC, York, 2016</p>
		<p>15/06/2016: Our team secures the <span style="color:red">2nd</span> place at ActivityNet Challenge 2016 in activity detection task [<a href="http://activity-net.org/challenges/2016/program.html">Results</a>].
		Our approach is described in <a href="https://arxiv.org/abs/1607.01979">arxiv technical report</a>.</p>

	</div>
	
	<div class="container">

	<h2 class="hh" style="margin-bottom:40px">Publications <a href="https://scholar.google.com/citations?user=w8XHUMIAAAAJ&hl=en" target="_blank"><img src="resources/icons/google_scholar.png" ></a> </h2>
	
	<div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./resources/projects/accv2016/icon.svg">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Comming soon</div>
            <div class="pubd">Comming soon</div>
            <div class="puba">Gurkirt Singh, Suman Saha and Fabio Cuzzolin.</div>
            <div class="pubv">ACCV 2016 </div>
            <div class="publ">
				<ul>
				  <li><a href="#">PDF</a></li>
				  <li><a href="#">Code</a></li>
				  <!-- <li><a href="http://arxiv.org/abs/1506.02078">Supplymentry</a></li> -->
				</ul>
            </div>
          </div>
        </div>
      </div>
    </div>
	
	<div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./resources/projects/BMVC2016icon.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos</div>
            <div class="pubd">In this work we propose a new approach to the spatio-temporal
			localisation (detection) and classification of multiple concurrent actions within
			temporally untrimmed videos. We demonstrate the performance of our algorithm on the challenging
			UCF101, J-HMDB-21 and LIRIS-HARL datasets, achieving new state-of-the-art results
			across the board and significantly lower detection latency at test time.</div>
            <div class="puba">Suman Saha, Gurkirt Singh, Michael Sapienza, Philip H. S. Torr, Fabio Cuzzolin.</div>
            <div class="pubv">BMVC 2016 </div>
            <div class="publ">
				<ul>
				  <li><a href="http://sahasuman.bitbucket.org/bmvc2016/index.html#publication">PDF</a></li>
				  <li><a href="http://sahasuman.bitbucket.org/bmvc2016/index.html">Project page</a></li>
				  <li><a href="https://bitbucket.org/sahasuman/bmvc2016_code">Code</a></li>
				  <li><a href="https://www.youtube.com/watch?v=vBZsTgjhWaQ">Demo Video</a></li>
				</ul>
            </div>
          </div>
        </div>
      </div>
    </div>
		
	<div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./resources/projects/actnet2016.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Untrimmed Video Classification for Activity Detection: submission to ActivityNet Challenge</div>
            <div class="pubd">In this work we propose a simple, yet effective, method for the temporal detection
						of activities in temporally untrimmed videos with the help of untrimmed classification.
			            This method secured the <span style="color:red">2nd</span> place at ActivityNet
						Challenge 2016 in activity detection task [<a href="http://activity-net.org/challenges/2016/program.html">Results</a>]</div>
            <div class="puba">Gurkirt Singh and Fabio Cuzzolin.</div>
            <div class="pubv">CVPR 2016 ActivityNet workshop, 2nd place in detection task.</div>
            <div class="publ">
				<ul>
				  <li><a href="https://arxiv.org/pdf/1607.01979v2.pdf">PDF</a></li>
				  <li><a href="https://github.com/gurkirt/actNet-inAct">Code</a></li>
				  <!-- <li><a href="http://arxiv.org/abs/1506.02078">Supplymentry</a></li> -->
				</ul>
            </div>
          </div>
        </div>
      </div>
    </div>
	
	<div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./resources/projects/continousGesture.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Continuous gesture recognition from articulated poses</div>
            <div class="pubd">This paper addresses the problem of continuous gesture recognition from articulated poses.
						Unlike the common isolated recognition scenario, the gesture boundaries are here unknown,
						and one has to solve two problems: segmentation and recognition.
						This is cast into a labeling framework, namely every site (frame) must be assigned a label (gesture ID).
						The inherent constraint for a piece-wise constant labeling is satisfied by solving a
						global optimization problem with a smoothness term.
						This mehtod secured 7th place in gesture
						detection task in ChaLearn LaP Challenge using only skeleton data.</div>
            <div class="puba">Georgios Evangelidis, Gurkirt Singh, Radu Patrice Horaud.</div>
			<div class="pubv">ECCV 2014 workshop</div>
            <div class="publ">
				<ul>
				  <li><a href="https://hal.archives-ouvertes.fr/hal-01082981/document">PDF</a></li>
				  <li><a href="https://team.inria.fr/perception/research/skeletalquads/">Project Page</a></li>
				  <li><a href="https://www.youtube.com/watch?v=d6wCy0CbYiE">Demo Video</a></li>
				</ul>
            </div>
          </div>
        </div>
      </div>
    </div>
	
	<div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./resources/projects/skeletalQuads.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Skeletal Quads:Human action recognition using joint quadruples</div>
            <div class="pubd"> In this context, we propose a local skeleton descriptor that encodes
								the relative position of joint quadruples. Such a coding implies a
								similarity normalisation transform that leads to a compact (6D or 5D)
								view-invariant skeletal feature, referred to as skeletal quad.
								In the references below, we use this descriptor in conjunction
								with FIsher kernel in order to encode gesture or action (sub)sequences.
								The short length of the descriptor compensates for the large inherent
								dimensionality associated to Fisher vectors.</div>
            <div class="puba">Georgios Evangelidis, Gurkirt Singh, Radu Patrice Horaud.</div>
			<div class="pubv">ICPR 2014</div>
            <div class="publ">
				<ul>
				  <li><a href="https://hal.archives-ouvertes.fr/file/index/docid/1064662/filename/main.pdf">PDF</a></li>
				  <li><a href="https://team.inria.fr/perception/research/skeletalquads/">Project Page</a></li>
				  <li><a href="https://team.inria.fr/perception/files/2015/05/SkeletalQuadCode.zip">Code</a></li> 
				</ul>
            </div>
          </div>
        </div>
      </div>
    </div>
	
	<div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./resources/projects/masterThesis.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Frame-wise representations of depth videos for action recognition</div>
            <div class="pubd"> We present three types of depth data representation from depth frames, which are referred as single-reference representation, multiple-reference representation and Quad representation.</div>
            <div class="puba">Gurkirt Singh</div>
			<div class="pubv">Master thesis, INRIA and Grenoble Institute of Technology, France, 2013</div>
			<div class="puba">Supervisors: Dr. Radu Horaud and Dr. Georgios Evangelidis</div>
            <div class="publ">
				<ul>
				  <li><a href="./resources/projects/masterReport.pdf">PDF</a></li>
				  <li><a href="https://sites.google.com/site/gurkirtcv/Research/master-thesis">Project Page</a></li>
				</ul>
            </div>
          </div>
        </div>
      </div>
    </div>
	
	<div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="./resources/projects/btechThesis.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Categorizing Abnormal behavior from and indoor overhead camera</div>
            <div class="pubd"> We propose an approach using overhead camera to detect abnormal activties with help trajectory classification.</div>
            <div class="puba">Gurkirt Singh</div>
			<div class="pubv">Bachelor thesis, University of Edinburgh and VIT University, 2010</div>
			<div class="puba">Supervisor: Dr. Bob Fisher</div>
            <div class="publ">
				<ul>
				  <li><a href="http://homepages.inf.ed.ac.uk/rbf/FORUMTRACKING/SINGH/GurkirtSingh.pdf">PDF</a></li>
				  <li><a href="http://homepages.inf.ed.ac.uk/rbf/FORUMTRACKING/">Database and Project</a></li>
				  
				</ul>
            </div>
          </div>
        </div>
      </div>
    </div>
	
	
	</div>
	
	<div class="container">

		<h2 class="hh">Contests</h2>
		<p>ActivityNet Large Scale Activity Recognition Challenge, 2016: <span style="color:red">Actvity detection</span>, Rank: 2/6, Untrimmed Video Classification, Rank: 10/24.</p>
		<p>ChaLearn Looking at People Challenge, 2014 , Gesture detection, Rank: 7/17.</p>
		<p>ChaLearn Looking at People Challenge, 2013 , Gesture detection, Rank: 17/54.</p>

	</div>
	
	<div class="container">
		<h2 class="hh">MISC</h2>
		<p> I made an attempt to compile recent works on action recognition in more searchable format.
		Check it out on my <a href="https://sites.google.com/site/gurkirtcv/Research/action-recognition-review">older page</a></p>
		<p> My old research <a href="https://sites.google.com/site/gurkirtcv/Research">page</a>, it has link to my master thesis and bachelor thesis.</p>
		<p><a href="read/index.html">Citation Graph: part of submission from reading Group-1 at ICVSS 2016 (only works in firefox)</a></p>
		<div style="margin-bottom:30px"></div>
	</div>
	
	<div class="container">
		
		<a style="margin-bottom:400px" href="#"> ==================================================  </a></div>
	<div style="margin-bottom:30px"></div>
	</div>
	
	<div class="container">
	<!-- Counter Code START -->
	<a href="http://www.e-zeeinternet.com/" target="_blank"><img src="http://www.e-zeeinternet.com/count.php?page=1153724&style=default&nbdigits=5&reloads=1" alt="Free Counter" border="0" ></a><!-- Counter Code END -->
	<!-- Counter Code START --><a href="http://www.e-zeeinternet.com/" target="_blank"><img src="http://www.e-zeeinternet.com/count.php?page=1153725&style=default&nbdigits=5" alt="Free Web Counter" border="0" ></a><!-- Counter Code END -->
	<div style="margin-bottom:30px"></div>
	</div>
	<div class="container"><footer> <p> copyright @ gurkirt singh </p></div>
	<!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="./bootstrap/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="./bootstrap/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="./bootstrap/ie10-viewport-bug-workaround.js"></script>
	
</body>
</html>
