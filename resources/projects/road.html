<!DOCTYPE html>
<!-- saved from url=(0050)http://getbootstrap.com/examples/starter-template/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="ROAD dataset page">
    <meta name="author" content="Gurkirt Singh">
    <link rel="icon" href="../../resources/icons/R.webp">
    <title>ROAD Dataset </title>

    <!-- Bootstrap core CSS -->
    <link href="../../bootstrap/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../bootstrap/style.css" rel="stylesheet">
	<link href="../../bootstrap/css" rel="stylesheet" type="text/css">
	
  <script src="../../bootstrap/ie-emulation-modes-warning.js"></script>


  </head>
<!-- <body> -->
  <body id="page">

  <!-- </body> class="bg-dark" data-new-gr-c-s-check-loaded="14.997.0" data-gr-ext-installed=""> -->
    <!-- <div id="StayFocusd-infobar" style="display:none;"> -->
      <!-- <img src="chrome-extension://laankejkbhbdhmipfmgcngdelahlfoji/common/img/eye_19x19_red.png">
      <span id="StayFocusd-infobar-msg"></span>
      <span id="StayFocusd-infobar-links">
          <a id="StayFocusd-infobar-never-show">hide forever</a>&nbsp;&nbsp;|&nbsp;&nbsp;
          <a id="StayFocusd-infobar-hide">hide once</a>
      </span>
  </div> -->


<center>
    <div class="container"> 
			<br>
			<img src="road_frames.jpg">
      <br>
			<h4> ROAD: The ROad event Awareness Dataset for Autonomous Driving</h4>
			<nav id="home-nav" class="site-nav">
								
				<a class="btn" href="https://arxiv.org/abs/2102.11585" target="_blank" rel="noopener me">[Paper]</a>
				<a class="btn" href="https://github.com/gurkirt/road-dataset" target="_blank" rel="noopener me">[Data]</a>
        <a class="btn" href="https://github.com/gurkirt/3D-RetinaNet" target="_blank" rel="noopener me">[Code]</a>
				<a class="btn" href="https://sites.google.com/view/roadchallangeiccv2021/" target="_blank" rel="noopener me">[Challenge]</a>
		</div>
  
		<!-- <div id="home-footer">
			<p>
				© 2021 Gurkirt Singh</a>
			</p>
		</div> -->

    <div class="container"><footer> <p> © 2021 <a href="http://gurkirt.github.io/">Gurkirt Singh </a></p></div>
  </center>

	
	<!-- <div class="container">

    <h2 class="hh">News</h2>
    <p> June 2020: I am co-oragnising <a href="https://saras-esad.grand-challenge.org/">SARAS-ESAD challenge</a> at <a href="https://2020.midl.io/">MIDL 2020</a> in Montreal, Canada</p>
    <p> Feb 2020: I joined Computer Vision Lab at ETH Zurich</p>
    <p> Aug 2019: I am selected in Doctoral Consortium ICCV 2019</p>
    <p> Aug 2019: I am selected as the best reviewer for ICCV 2019</p>
    <p> June 2019: Presenting <a href="https://arxiv.org/abs/1811.07157">causal representations</a> work at <a href="http://www.robots.ox.ac.uk/~seminars/seminars/">Oxford Robotics Research Group Seminars</a>, see you there on 24th</p>
    <p>Sept 2018: Our paper on "Transition Matrix network" is accpted at ACCV Perth, 2018</p>
    <p>Aug 2018: Our paper on "Predicting Action Tubes" is accpted at AHB2018 workshop at ECCV, 2018</p>
    <p>July 2018: Our paper on "Incremental Tube Construction for Human Action Detection" is accpted at BMVC, York, 2018</p>
    <p>Dec 2017: Pytorch implementation of our work on <a href="https://arxiv.org/pdf/1611.08563.pdf">Online Real-time action Detection</a> is available on <a href="https://github.com/gurkirt/realtime-action-detection">GitHub</a></p>
    <p>Dec 2017: Pytorch implementation of <a href="https://arxiv.org/pdf/1406.2199.pdf">Two stream</a> InceptionV3 trained for action recognition using <a href="https://deepmind.com/research/open-source/open-source-datasets/kinetics/">Kinetics</a> dataset is available on <a href="https://github.com/gurkirt/realtime-action-detection">GitHub</a></p>
		<p>July 2017: My work at Disney Research Pittsburgh with <a href="http://cs.brown.edu/~ls/">Leonid Sigal</a> and <a href="https://ps.is.tuebingen.mpg.de/person/alehrmann">Andreas Lehrmann</a> secured 2nd place in <a href="http://vuchallenge.org/charades.html">charades challenge</a>, 
    second only to DeepMind entery</p>
		<p>July 2017: <span style="color:blue">Two</span> paper got accpted at ICCV 2017, avaiable below. 
		<p>June 2016: Our paper on "Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos" is accpted at BMVC, York, 2016</p>
		<p>June 2016: Our team secures the <span style="color:blue">2nd</span> place at ActivityNet Challenge 2016 in activity detection task [<a href="http://activity-net.org/challenges/2016/program.html">Results</a>].
		Our approach is described in <a href="https://arxiv.org/abs/1607.01979">arxiv technical report</a>.</p>

	</div> -->
	
</body>
</html>